{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 19 03:33:30 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   38C    P0    60W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  Off  | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   36C    P0    59W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  Off  | 00000000:00:06.0 Off |                    0 |\n",
      "| N/A   36C    P0    60W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM...  Off  | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   37C    P0    58W / 400W |      0MiB / 40536MiB |     21%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from diffusers import AutoencoderKL, DDPMScheduler, PNDMScheduler, StableDiffusionPipeline, UNet2DConditionModel\n",
    "from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n",
    "from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from multiprocessing import Pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_samples = 5\n",
    "prompt = [\"\"] * num_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = \"AUTH_TOKEN\"\n",
    "def load_pipeline(step: int):\n",
    "    if step == 0:\n",
    "        # load the original model\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", use_auth_token=TOKEN)\n",
    "    else:\n",
    "        # fine tuned models on Google cloud compute engine\n",
    "        model_path = f\"/user/disks/sdc/runs/finetune_cocomelon/step-{step}\"\n",
    "        text_encoder = CLIPTextModel.from_pretrained(\n",
    "            model_path, subfolder=\"text_encoder\"\n",
    "        )\n",
    "        vae = AutoencoderKL.from_pretrained(\n",
    "            model_path, subfolder=\"vae\"\n",
    "        )\n",
    "        unet = UNet2DConditionModel.from_pretrained(\n",
    "            model_path, subfolder=\"unet\"\n",
    "        )\n",
    "\n",
    "        tokenizer = CLIPTokenizer.from_pretrained(\n",
    "            \"CompVis/stable-diffusion-v1-4\", subfolder=\"tokenizer\", use_auth_token=TOKEN\n",
    "        )\n",
    "\n",
    "        pipe = StableDiffusionPipeline(\n",
    "            text_encoder=text_encoder,\n",
    "            vae=vae,\n",
    "            unet=unet,\n",
    "            tokenizer=tokenizer,\n",
    "            scheduler=PNDMScheduler(\n",
    "                beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", skip_prk_steps=True\n",
    "                ),\n",
    "            # safety_checker=StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"),\n",
    "            feature_extractor=CLIPFeatureExtractor.from_pretrained(\"openai/clip-vit-base-patch32\"),\n",
    "            )\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_grid(grid, first_step, last_step, prompt):\n",
    "    counter = 0\n",
    "    root_dir = Path(\"/home/user/thumbnail-stable-diffusion/data\")\n",
    "    \n",
    "    name=f\"\"\n",
    "    while True:\n",
    "        counter += 1\n",
    "        fname = f\"{prompt}_step_{first_step}_{last_step}_{counter}.png\"\n",
    "        path =  root_dir / fname\n",
    "        if not path.exists():\n",
    "            grid.save(str(root_dir / fname))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(steps, prompt):\n",
    "    tot_images = []\n",
    "    for step in steps:\n",
    "        pipe = load_pipeline(step)\n",
    "        pipe.to(\"cuda\")\n",
    "        images = pipe(prompt).images\n",
    "        tot_images.extend(images)\n",
    "        \n",
    "    grid = image_grid(tot_images, rows=len(steps), cols=len(prompt))\n",
    "    save_grid(grid, steps[0], steps[-1], prompt[0])\n",
    "    # grid.save(f\"{prompt[0]}_step_{steps[0]}_{steps[-1]}_2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'trained_betas'} was not found in config. Values will be initialized to default values.\n",
      "100%|██████████| 51/51 [00:22<00:00,  2.23it/s]\n",
      "100%|██████████| 51/51 [00:22<00:00,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "prompt = [\"Birthday at the farm song with cocomelon\"] * 5\n",
    "steps = [5000*i for i in range(2)]\n",
    "# steps = [5000*i for i in range(2)]\n",
    "generate_samples(steps, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try to make the generate faster by running on multiple GPUs\n",
    "\n",
    "\n",
    "def generate_sample_single_step_single_gpu(gpu_idx, step, prompt):\n",
    "    \"\"\"\n",
    "    takes a gpu index and a step number (number of fine tuning steps) and generates samples\n",
    "    \"\"\"\n",
    "    device = f\"cuda:{gpu_idx}\"\n",
    "    if step == 0:\n",
    "        # load the original model\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", use_auth_token=TOKEN)\n",
    "    else:\n",
    "        # fine tuned models\n",
    "        model_path = f\"/user/disks/sdc/runs/finetune_cocomelon/step-{step}\"\n",
    "        text_encoder = CLIPTextModel.from_pretrained(\n",
    "            model_path, subfolder=\"text_encoder\"\n",
    "        )\n",
    "        vae = AutoencoderKL.from_pretrained(\n",
    "            model_path, subfolder=\"vae\"\n",
    "        )\n",
    "        unet = UNet2DConditionModel.from_pretrained(\n",
    "            model_path, subfolder=\"unet\"\n",
    "        )\n",
    "\n",
    "        tokenizer = CLIPTokenizer.from_pretrained(\n",
    "            \"CompVis/stable-diffusion-v1-4\", subfolder=\"tokenizer\", use_auth_token=TOKEN\n",
    "        )\n",
    "\n",
    "        pipe = StableDiffusionPipeline(\n",
    "            text_encoder=text_encoder,\n",
    "            vae=vae,\n",
    "            unet=unet,\n",
    "            tokenizer=tokenizer,\n",
    "            scheduler=PNDMScheduler(\n",
    "                beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", skip_prk_steps=True\n",
    "                ),\n",
    "            # safety_checker=StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"),\n",
    "            feature_extractor=CLIPFeatureExtractor.from_pretrained(\"openai/clip-vit-base-patch32\"),\n",
    "            )\n",
    "    \n",
    "    pipe.to(\"cuda\")\n",
    "    images = pipe(prompt).images\n",
    "    return (images, step)\n",
    "\n",
    "\n",
    "def generate_samples_multi_gpu(steps, prompt):\n",
    "    tot_images = []\n",
    "\n",
    "\n",
    "    # a pool of 4 processes where each one call generate_sample_single_step_single_gpu and gets the samples in return\n",
    "    with Pool(processes=len(steps)) as pool:\n",
    "        results = pool.starmap(generate_sample_single_step_single_gpu, [(i, step, prompt) for i, step in enumerate(steps)])\n",
    "\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "    tot_images = [images for images, _ in results]\n",
    "\n",
    "    grid = image_grid(tot_images, rows=len(steps), cols=len(prompt))\n",
    "\n",
    "    save_grid(grid, steps[0], steps[-1], prompt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [5000*i for i in range(2)]\n",
    "prompt = [\"playing with baloons\"] * 5\n",
    "generate_samples_multi_gpu(steps, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c9bc848d6614b8aa27f579200bd21c2c3f003b467cb1ae4cb30b062103624bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
